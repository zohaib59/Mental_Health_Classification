# Mental_Health_Classification
# Burnout Risk Prediction using Machine Learning
Burnout in the workplace is real‚Äîand preventable.

I recently built a machine learning pipeline to **predict burnout risk** using a real-world HR dataset. The project used:

‚úÖ 12 ML models (XGBoost, CatBoost, LightGBM, RandomForest, MLP, etc.)  
‚úÖ Label encoding & feature scaling  
‚úÖ EDA with outlier detection & class imbalance  
‚úÖ Accuracy, precision, recall, F1-score, confusion matrix  
‚úÖ Model interpretability using SHAP  

This project gave me deep insight into:
- How different algorithms handle tabular classification
- The importance of preprocessing and feature engineering
- How scalable ensemble methods outperform simple linear models

#MachineLearning #MentalHealth #Burnout #HRAnalytics #Python #XGBoost #DataScience #AI #CatBoost #LightGBM #NeuralNetworks #OpenToWork

This project aims to predict **burnout risk** using a comprehensive suite of **machine learning models**, based on demographic and professional features from an HR dataset.

By training and comparing over **12 classification models**, we evaluate performance, detect outliers, 
encode categories, scale features, and assess model accuracy, precision, recall, F1-score, and confusion matrix.

## Key Features

- üîç EDA (Boxplots, null/duplicate detection, class distribution)
- üîÑ Preprocessing: Label encoding, scaling
- ü§ñ ML Models: Logistic Regression, Ridge, Random Forest, Gradient Boosting, XGBoost, CatBoost, LGBM, Neural Net (MLP), etc.
- üìä Model Evaluation: Accuracy, Precision, Recall, F1-score, Confusion Matrix
- üì¶ Feature Importance (via SHAP or tree-based models)
- ‚úÖ Training/Testing Split with Cross Validation


- Python 3.8+
- Scikit-learn
- XGBoost
- CatBoost
- LightGBM
- SHAP (for model explainability)
- Seaborn & Matplotlib for Visualization
- Pandas, NumPy for data handling


